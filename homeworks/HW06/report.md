# HW06 – Report

> Файл: `homeworks/HW06/report.md`  

## 1. Dataset

- Какой датасет выбран: `S06-hw-dataset-01.csv`
- Размер: (12000 строк, 30 столбцов)
- Целевая переменная: target (бинарная классификация: 0 - 67.66%, 1 - 32.34%)
- Признаки: 
24 числовых признака (num01-num24) - стандартизированные значения
3 категориально-подобных признака:
cat_contract (3 уникальных значения: 0, 1, 2)
cat_region (5 уникальных значений: 0-4)
cat_payment (4 уникальных значений: 0-3)
tenure_months - целочисленный признак (0-120 месяцев)
id - идентификатор (исключен из признаков)

## 2. Protocol

- Разбиение: train/test (75%/25%, random_state=42, stratify=y)
- Подбор: CV на train (5 фолдов, StratifiedKFold, оптимизация ROC-AUC)
- Метрики:
accuracy - базовая метрика для общего качества
F1-score - учитывает дисбаланс классов (32.34% класса 1)
ROC-AUC - основная метрика для бинарной классификации, устойчива к дисбалансу, позволяет оценить разделяющую способность модели

## 3. Models
Использованные модели:

- DummyClassifier (baseline):
Стратегия: most_frequent
Без подбора гиперпараметров

- LogisticRegression (baseline из S05):
Pipeline: StandardScaler + LogisticRegression
Подбор: C (0.1, 1.0, 10.0), penalty='l2', solver='lbfgs'
Максимальное количество итераций: 4000

- DecisionTreeClassifier:
Подбор гиперпараметров:
max_depth: [None, 3, 5, 8]
min_samples_leaf: [1, 5, 10, 20]
ccp_alpha: [0.0, 0.001, 0.005, 0.01]
Контроль сложности через все три параметра
RandomForestClassifier:

- Количество деревьев: 600 (фиксировано)
Подбор:
max_depth: [None, 6, 10]
min_samples_leaf: [1, 5, 10]
max_features: ['sqrt', 0.5]

- HistGradientBoostingClassifier (boosting):
Подбор:
learning_rate: [0.03, 0.05, 0.1]
max_depth: [2, 3, None]
max_leaf_nodes: [15, 31, 63]


## 4. Results


|Модель|Accuracy|F1-score|ROC-AUC|
|-|-|-|-|
|HistGradientBoosting|0.9363|0.8982|0.9747|
|RandomForest|0.9347|0.8943|0.9706|
|DecisionTree|0.8633|0.7849|0.9105|
|LogReg(scaled)|0.8297|0.7147|0.8789|
|Dummy(most_frequent)|0.6767|0.0000|0.5000|
- Победитель (по ROC-AUC или по согласованному критерию) и краткое объяснение

## 5. Analysis

- Устойчивость: Для проверки устойчивости лучшей модели (HistGradientBoosting) проведено 20 прогонов с разными random_state (0-19):\
Accuracy: mean=0.9376, std=0.0020  
ROC-AUC: mean=0.9742, std=0.0007
- Ошибки: confusion matrix 
[[1924  108]
 [  82  886]]
 
Вывод: Модель показывает высокую устойчивость:

Стандартное отклонение ROC-AUC всего 0.0007, что свидетельствует о стабильности разделяющей способности модели независимо от начального состояния генератора случайных чисел.

Низкая дисперсия accuracy (std=0.0020) подтверждает надежность классификационных предсказаний.

Confusion matrix стабильна по всем прогонам, что показывает воспроизводимость ошибок.
- Интерпретация: permutation importance top-10:\
['num19',
 'num18',
 'num07',
 'num04',
 'num24',
 'num14',
 'num01',
 'num20',
 'num22',
 'num06']

## 6. Conclusion

1. Ансамбли значительно превосходят одиночные модели - RandomForest и HistGradientBoosting дали ROC-AUC >0.97 против 0.91 у DecisionTree и 0.88 у LogisticRegression.

2. Boosting показал лучший результат - HistGradientBoosting превзошел RandomForest, что согласуется с теорией: boosting последовательно исправляет ошибки предыдущих моделей.

3. Контроль сложности важен для деревьев - DecisionTree с подобранными гиперпараметрами (min_samples_leaf=20) показал неплохой результат, но все равно уступает ансамблям из-за высокой дисперсии.

4. ROC-AUC - надежная метрика для бинарной классификации - Позволила объективно сравнить модели, несмотря на дисбаланс классов.